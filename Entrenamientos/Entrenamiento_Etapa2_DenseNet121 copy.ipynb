{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hKjVXhbjim2Z"
      },
      "outputs": [],
      "source": [
        "# Definir la ruta de las carpetas\n",
        "ruta_DE2_train = \"/Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/train\"\n",
        "ruta_DE2_val = \"/Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/val\"\n",
        "ruta_DE2_test = \"/Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yzwMvoy8HOCL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/envs/mamografia/lib/python3.11/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n"
          ]
        }
      ],
      "source": [
        "# Importar el Generador de datos\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ITZOOG-Xh3DD"
      },
      "outputs": [],
      "source": [
        "# Creamos el generador para las carpetas \"train\", \"val\" y \"test\"\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBydv7-wjtJx",
        "outputId": "34662e5d-1b75-4417-b829-83e425f29007"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 232 images belonging to 3 classes.\n",
            "Found 50 images belonging to 3 classes.\n",
            "Found 50 images belonging to 3 classes.\n",
            "{'birads_3': 0, 'birads_4': 1, 'birads_5': 2}\n"
          ]
        }
      ],
      "source": [
        "# Cargar datos en Keras\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    ruta_DE2_train,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    ruta_DE2_val,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    ruta_DE2_test,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(train_gen.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocXTLKc4x4mv",
        "outputId": "0b2809a4-c5ce-4e04-97f4-3f6685ae8471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 0.3925549915397631, 1: 2.8641975308641974, 2: 9.666666666666666}\n"
          ]
        }
      ],
      "source": [
        "# Calcular Class Weights\n",
        "# birads_3: 0\n",
        "# birads_4: 1\n",
        "# birads_5: 2\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "y_train = train_gen.classes\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "print(class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGVj8dMQ2Tp3",
        "outputId": "ef465b5a-c35e-41ae-e191-fc732f594fbf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-25 17:26:33.631522: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
            "2026-01-25 17:26:33.631711: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
            "2026-01-25 17:26:33.631719: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
            "2026-01-25 17:26:33.631950: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2026-01-25 17:26:33.631994: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "# Modelo con DenseNet121 (Transfer Learning)\n",
        "# Construyendo el modelo usando la CNN preentrenada DenseNet121\n",
        "base_model = DenseNet121(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Vw6BUlio9T-c"
      },
      "outputs": [],
      "source": [
        "# Clasificador\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(3, activation=\"softmax\")(x) # 3: es el número de clases\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VX9VXYjdAu_w"
      },
      "outputs": [],
      "source": [
        "# Compilación (enfoque clínico)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\n",
        "        \"accuracy\",\n",
        "        tf.keras.metrics.AUC(name=\"auc\", multi_label=True),\n",
        "        tf.keras.metrics.Precision(name=\"precision\"),\n",
        "        tf.keras.metrics.Recall(name=\"recall\")\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G8bvJAxDFN5-"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=7,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\",\n",
        "        factor=0.3,\n",
        "        patience=4,\n",
        "        min_lr=1e-6\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        \"densenet121_etapa2_birads3_4_5.keras\",\n",
        "        monitor=\"val_loss\",\n",
        "        save_best_only=True\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VBxg0BqIFHRO",
        "outputId": "329c1ad3-bca1-429e-8e17-b1185542c7d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-25 17:27:23.227464: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.4871 - auc: 0.4530 - loss: 3.1152 - precision: 0.4909 - recall: 0.4655 - val_accuracy: 0.3800 - val_auc: 0.6587 - val_loss: 1.0442 - val_precision: 0.5000 - val_recall: 0.2800 - learning_rate: 1.0000e-04\n",
            "Epoch 2/40\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 938ms/step - accuracy: 0.2974 - auc: 0.4590 - loss: 2.3896 - precision: 0.3005 - recall: 0.2759 - val_accuracy: 0.0800 - val_auc: 0.6360 - val_loss: 2.1253 - val_precision: 0.0488 - val_recall: 0.0400 - learning_rate: 1.0000e-04\n",
            "Epoch 3/40\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 932ms/step - accuracy: 0.3319 - auc: 0.4220 - loss: 2.7599 - precision: 0.3180 - recall: 0.2974 - val_accuracy: 0.2000 - val_auc: 0.6475 - val_loss: 1.6045 - val_precision: 0.1515 - val_recall: 0.1000 - learning_rate: 1.0000e-04\n",
            "Epoch 4/40\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 934ms/step - accuracy: 0.3103 - auc: 0.4547 - loss: 2.5288 - precision: 0.3151 - recall: 0.2974 - val_accuracy: 0.3400 - val_auc: 0.6529 - val_loss: 1.3086 - val_precision: 0.2581 - val_recall: 0.1600 - learning_rate: 1.0000e-04\n",
            "Epoch 5/40\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 936ms/step - accuracy: 0.2974 - auc: 0.5051 - loss: 2.1529 - precision: 0.2823 - recall: 0.2543 - val_accuracy: 0.2600 - val_auc: 0.6485 - val_loss: 1.4519 - val_precision: 0.2500 - val_recall: 0.1600 - learning_rate: 1.0000e-04\n",
            "Epoch 6/40\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 929ms/step - accuracy: 0.3664 - auc: 0.5307 - loss: 2.0229 - precision: 0.3653 - recall: 0.3448 - val_accuracy: 0.2800 - val_auc: 0.6596 - val_loss: 1.2840 - val_precision: 0.3333 - val_recall: 0.1800 - learning_rate: 3.0000e-05\n",
            "Epoch 7/40\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 940ms/step - accuracy: 0.3707 - auc: 0.4703 - loss: 2.1423 - precision: 0.3850 - recall: 0.3534 - val_accuracy: 0.2400 - val_auc: 0.6592 - val_loss: 1.4060 - val_precision: 0.2258 - val_recall: 0.1400 - learning_rate: 3.0000e-05\n",
            "Epoch 8/40\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 921ms/step - accuracy: 0.3578 - auc: 0.5583 - loss: 1.8323 - precision: 0.3507 - recall: 0.3190 - val_accuracy: 0.2600 - val_auc: 0.6654 - val_loss: 1.4099 - val_precision: 0.2333 - val_recall: 0.1400 - learning_rate: 3.0000e-05\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=40,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar modelo\n",
        "model.save(\"densenet121_etapa2_birads_3-5_gradcam.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step \n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(test_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50, 3)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.3054062 , 0.6738747 , 0.02071914],\n",
              "       [0.8490527 , 0.06433421, 0.08661313],\n",
              "       [0.6474466 , 0.17456596, 0.17798746],\n",
              "       [0.29826802, 0.67851573, 0.02321629],\n",
              "       [0.49525684, 0.43923908, 0.06550407]], dtype=float32)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['birads_3', 'birads_4', 'birads_5']\n"
          ]
        }
      ],
      "source": [
        "class_names = list(test_gen.class_indices.keys())\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 520ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    birads_3       0.85      0.40      0.54        43\n",
            "    birads_4       0.12      0.33      0.18         6\n",
            "    birads_5       0.07      1.00      0.13         1\n",
            "\n",
            "    accuracy                           0.40        50\n",
            "   macro avg       0.35      0.58      0.28        50\n",
            "weighted avg       0.75      0.40      0.49        50\n",
            "\n",
            "[[17 14 12]\n",
            " [ 3  2  1]\n",
            " [ 0  0  1]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Predicciones\n",
        "y_pred = model.predict(test_gen, verbose=1)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Etiquetas reales\n",
        "y_true = test_gen.classes\n",
        "\n",
        "# Reporte\n",
        "print(classification_report(y_true, y_pred_classes, target_names=class_names))\n",
        "\n",
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    \"image_path\": test_gen.filepaths,\n",
        "    \"y_true\": y_true,\n",
        "    \"y_pred\": y_pred_classes\n",
        "})\n",
        "\n",
        "results[\"correct\"] = results[\"y_true\"] == results[\"y_pred\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>y_true</th>\n",
              "      <th>y_pred</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/test/birads_3/BIRADS_3_240.png</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/test/birads_3/BIRADS_3_241.png</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/test/birads_3/BIRADS_3_242.png</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/test/birads_3/BIRADS_3_243.png</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/test/birads_3/BIRADS_3_244.png</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                            image_path  \\\n",
              "0  /Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/test/birads_3/BIRADS_3_240.png   \n",
              "1  /Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/test/birads_3/BIRADS_3_241.png   \n",
              "2  /Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/test/birads_3/BIRADS_3_242.png   \n",
              "3  /Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/test/birads_3/BIRADS_3_243.png   \n",
              "4  /Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/test/birads_3/BIRADS_3_244.png   \n",
              "\n",
              "   y_true  y_pred  correct  \n",
              "0       0       1    False  \n",
              "1       0       0     True  \n",
              "2       0       0     True  \n",
              "3       0       1    False  \n",
              "4       0       0     True  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>y_true</th>\n",
              "      <th>y_pred</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>/Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/test/birads_4/BIRADS_4_39.png</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                            image_path  \\\n",
              "48  /Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/test/birads_4/BIRADS_4_39.png   \n",
              "\n",
              "    y_true  y_pred  correct  \n",
              "48       1       2    False  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "birads4_wrong = results[\n",
        "    (results.y_true == 1) & (results.correct == False)\n",
        "]\n",
        "\n",
        "birads4_wrong.sample(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>y_true</th>\n",
              "      <th>y_pred</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>/Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/test/birads_4/BIRADS_4_35.png</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                            image_path  \\\n",
              "44  /Users/claracelestechavezcotrina/Downloads/DATA_TESIS/dataset_etapa2/test/birads_4/BIRADS_4_35.png   \n",
              "\n",
              "    y_true  y_pred  correct  \n",
              "44       1       1     True  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "birads4_correct = results[\n",
        "    (results.y_true == 1) & (results.correct == True)\n",
        "]\n",
        "\n",
        "birads4_correct.sample(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_path = birads4_wrong.sample(1).image_path.values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Cargo imagen\n",
        "img, img_array = load_image(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mamografia",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
